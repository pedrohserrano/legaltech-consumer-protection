{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_website(url):\n",
    "    \"\"\"Request given url\"\"\"\n",
    "\n",
    "    http = urllib3.PoolManager()\n",
    "    response = http.request('get', url)\n",
    "\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_site_soup(http_request_data):\n",
    "    \"\"\"Get the Soup of a given url\"\"\"\n",
    "    soup = BeautifulSoup(http_request_data, 'lxml')\n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_for_filter(soup, terms=(\"li\", {\"class\": \"ads-ad\"})):\n",
    "    \"\"\"Parses the given soup for given filters.\"\"\"\n",
    "\n",
    "    # get a list of all the elements, which shall be filtered for\n",
    "    specific = soup.find_all(terms[0], terms[1])\n",
    "\n",
    "    # get list of information about the elements and save each in a dictionary\n",
    "    entry_list = []\n",
    "    for entry in specific:\n",
    "        dic = {\n",
    "            \"text\": entry.find('a').text,\n",
    "            \"ad_link\": entry.find('div', {'class': 'ads-visurl'}).cite.text,\n",
    "            \"html\": entry\n",
    "        }\n",
    "        entry_list.append(dic)\n",
    "\n",
    "    return entry_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = 'https://www.ign.com/articles/super-nintendo-world-videos-show-off-mario-kart-and-yoshi-rides-merchandise-food-and-more'\n",
    "url = 'http://www.google.nl/search?q=fiets'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "http_request = request_website(url)\n",
    "soup = get_site_soup(http_request.data)\n",
    "#dir(http_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "linkElems =  soup.select('.r a')\n",
    "numOpen = min(5, len(linkElems))\n",
    "for i in range(numOpen):\n",
    "    print(linkElems[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "linkElems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "ad_list = parse_for_filter(soup, terms=(\"li\", {\"class\": \"ads-ad\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "metadata": {},
     "execution_count": 36
    }
   ],
   "source": [
    "ad_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/54797590/web-scraping-for-google-ads-using-python-and-beautifulsoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.journaldev.com/44755/scrape-google-search-using-python-beautifulsoup\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    " \n",
    "text = 'fiets'\n",
    "url = 'https://google.nl/search?q=' + text\n",
    "A = (\"Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2228.0 Safari/537.36\",\n",
    "       \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2227.1 Safari/537.36\",\n",
    "       \"Mozilla/5.0 (Windows NT 6.1; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/41.0.2227.0 Safari/537.36\",\n",
    "       )\n",
    " \n",
    "Agent = A[random.randrange(len(A))]\n",
    " \n",
    "headers = {'user-agent': Agent}\n",
    "r = requests.get(url, headers=headers)\n",
    " \n",
    "soup = BeautifulSoup(r.text, 'lxml')\n",
    "for info in soup.find_all('h3'):\n",
    "    print(info.text)\n",
    "    print('#######')"
   ]
  }
 ]
}