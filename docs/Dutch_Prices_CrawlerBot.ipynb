{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Persona_project.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1PmHk9J2I9m"
      },
      "source": [
        "## **Getting started**\n",
        "Price discrimination occurs when two users are shown inconsistent prices for the same product (e.g., Travelocity showing a select user a higher price for a particular hotel). Contrary to popular belief, price discrimination, in general, is not illegal in the United States, as the Robinsonâ€“Patman Act of 1936 (a.k.a. the Anti-Price Discrimination Act) is written to control the behaviour of product manufacturers and distributors, not consumer-facing enterprises. This project attempts to examine a potential inconsistency in product search results is due to the client-side state associated with the request.\n",
        "\n",
        "Within the framework of this project, a script that can be used for getting product information (product prices and details) and investigating a potential algorithmic unfairness was developed.  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qiUoJo0b_ETG"
      },
      "source": [
        "It is recommended for the user to be versed in the following:\n",
        "- **Python** programming language\n",
        "- Basics of **Data Analysis** \n",
        "- Be familiar with **[Pandas](https://pandas.pydata.org/docs/)** and **[Numpy](https://numpy.org/)** python libraries\n",
        "- Optionally: familiarity with **[Selenium](https://selenium-python.readthedocs.io/installation.html)** python library"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69Ywl2gsG882"
      },
      "source": [
        "For each e-commerce website, there is a script that is structurally identical to the scripts for other websites in [the project](https://github.com/maastrichtlawtech/persona-training-scripts/tree/main/Personalization).\n",
        "\n",
        "For the sake of simplicity, we are going to take a close look at the script for [Bol.com](https://www.bol.com/nl/nl/).\n",
        "\n",
        "For **[Selenium](https://selenium-python.readthedocs.io/installation.html)** python library, it is required to choose a webrowser for the webdriver which is a web framework that permits you to execute cross-browser tests. This tool is used for automating web-based application testing to verify that it performs expectedly. In our case, we are automating web-based programmatic collection of data and parsing data from a source. In that project, we are using [Firefox webrowser driver](https://github.com/mozilla/geckodriver/releases). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6mgy8ciItXk"
      },
      "source": [
        "## **Importing libraries**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doEWkGiEJa2W"
      },
      "source": [
        "First of all, we should import the libraries that we need to use. The code cell below imports Pandas, Numpy, Selenium and other utility libraries that will help to visualize the execution process.\n",
        "\n",
        "**Note**: we put all warnings that pop up during the execution process of the script off by using the method from the warnings library in order to have less verbose outputs to make the pipeline of the execution more readable. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccAQlqUOIp6d"
      },
      "source": [
        "# imports\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.webdriver.common.keys import Keys\n",
        "from selenium.common.exceptions import TimeoutException\n",
        "from selenium.webdriver import FirefoxOptions\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import argparse\n",
        "import warnings\n",
        "from user_agents import parse\n",
        "warnings.simplefilter(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiBdXa2fMGkD"
      },
      "source": [
        "## **Script usage parameters specification**\n",
        "\n",
        "To perform an experiment we need to specify the following parameters to the script:\n",
        "- A name of the experiment\n",
        "- A list of items of products to search\n",
        "- A website URL address\n",
        "- A path to [the Firefox webdriver](https://github.com/mozilla/geckodriver/releases) that was downloaded from the external source\n",
        "\n",
        "Optional: \n",
        "- A user-agent string which is essentially a string that specifies a device and browser acting on behalf of a user to send it to the website to rget a certain webpage layout according to the specified device \n",
        "- A proxy address to specify geolocation of a user to send it to the website\n",
        "\n",
        "The code cell below defines a function to parse the arguments explained above to execute the script.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EZPWMpa72LME"
      },
      "source": [
        "def get_parser():\n",
        "    # parse parameters\n",
        "    parser = argparse.ArgumentParser(description='Scrape Bolcom website')\n",
        "    parser.add_argument(\"--exp_name\", type=str, default=\"\", help=\"Experiment name\")\n",
        "    parser.add_argument(\"--items_list\", nargs='+', default=\"\", help=\"List of products to search\")\n",
        "    parser.add_argument(\"--web_page\", type=str, default=\"\", help=\"Website url\")\n",
        "    parser.add_argument(\"--exec_path\", type=str, default=\"\", help=\"Path to execute the webdriver\")\n",
        "    parser.add_argument(\"--ua_string\", type=str, default=\"\", help=\"User agent string to specify to identify/detect devices and browsers\")\n",
        "    parser.add_argument(\"--proxy\", type=str, default=\"\", help=\"Proxy to mimic IP Address Geolocation\")\n",
        "\n",
        "    return parser"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIBotOCcQA-E"
      },
      "source": [
        "## **Web crawling function**\n",
        "The code cell below defines a function to perform an iteration of data collection for the specified item. \n",
        "\n",
        "As input parameters, it takes a webdriver, an item to search for, delays which is a list of integer numbers to randomly delay the crawling process to mimic a real user behaviour, and a collected data list where we want to store the information. \n",
        "\n",
        "First, the script clicks on the banner button to update the page, after which it simulates the behavior of a person on the site by means of a delay. Next, the script finds the information input field (a search bar), inserts the name of the input product there and opens a page with a catalog of this product.\n",
        "\n",
        "After that, the script again simulates a person falling asleep for 5 seconds, after which it performs the process of collecting the necessary data about products from the catalog, writing it in the list (collected data). \n",
        "\n",
        "Each line with the product looks like this:\n",
        "\n",
        "- website name (Bol.com in our case)\n",
        "- item name (e.g., sneakers)\n",
        "- product name (e.g., Nike Air Force 1 (PS) Sneakers Kinderen - White/White-White)\n",
        "- seller information (e.g., Sneakersenzo.nl)\n",
        "- time when it was collected\n",
        "- price of the product\n",
        "\n",
        "**Note**: if the web driver cannot find the products on the web page, it ends the work by closing the script execution process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIuveRV3QBin"
      },
      "source": [
        "def iteration(driver, item, delays, collected_data):\n",
        "    # banner button BolCom click to update the search bar\n",
        "    banner_button = driver.find_element_by_class_name('omniture_main_logo')\n",
        "    # randomly choose a delay and freeze the execution to mimic a person usage\n",
        "    delay = np.random.choice(delays)\n",
        "    time.sleep(delay)\n",
        "    banner_button.click()   # press ENTER\n",
        "\n",
        "    delay = np.random.choice(delays)\n",
        "    time.sleep(delay)\n",
        "\n",
        "    # put a query in the search bar\n",
        "    search = driver.find_element_by_name(\"searchtext\")\n",
        "    search.send_keys(item)  # put it in the search field\n",
        "    search.submit()   # press ENTER\n",
        "\n",
        "    time.sleep(5)\n",
        "\n",
        "    timeout = 30\n",
        "    try:\n",
        "        main = WebDriverWait(driver, timeout).until(EC.visibility_of_element_located((By.ID, 'js_items_content')))\n",
        "        time.sleep(5)\n",
        "        articles = main.find_elements_by_class_name('product-item--row')                    # get all products from the page\n",
        "\n",
        "        for article in tqdm(articles):\n",
        "            price_header = article.find_elements_by_class_name('price-block__price')        # get a price object\n",
        "\n",
        "            if len(price_header) != 0:\n",
        "                # process price text\n",
        "                price = re.sub(r'[\\n\\r]+', '.', price_header[0].text)                       # get a price text\n",
        "                price = re.sub(\"\\-\", \"00\", price)\n",
        "\n",
        "                product_header = article.find_elements_by_class_name('product-title')       # get a product name\n",
        "\n",
        "                # get a seller name\n",
        "                try:\n",
        "                    seller = article.find_elements_by_class_name('product-seller__name')\n",
        "                    assert seller\n",
        "                except:\n",
        "                    seller = article.find_elements_by_class_name('product-seller')\n",
        "\n",
        "                if len(seller) == 0:    # case if there is no seller specified\n",
        "                    _seller = 'NaN'\n",
        "                else:\n",
        "                    _seller = seller[0].text    # get a seller name text\n",
        "\n",
        "                # temporary dictionary of the product data\n",
        "                temp = {\n",
        "                    'website': \"BolCom\",\n",
        "                    'item': item,\n",
        "                    'product': product_header[0].text,\n",
        "                    'seller': _seller,\n",
        "                    'time': pd.to_datetime('now').strftime(\"%Y-%m-%d %H:%M:%S\"),\n",
        "                    'price': price}\n",
        "\n",
        "                collected_data.append(temp)                                                     # append the data\n",
        "\n",
        "    except TimeoutException:\n",
        "        # driver.quit()\n",
        "        print(\"driver has not found products on the webpage\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVWlLWu8fqe0"
      },
      "source": [
        "## **Web crawling process execution**\n",
        "\n",
        "The code cell below defines the main function to perform iterations of data collection over all items in the list that the script received and parsed with get_parser function.\n",
        "\n",
        "The function defines and initializes a list of the possible delays to mimic user interaction with websites, a webdriver and webdriver options and the item list to search for. Also, here the web driver finds a cookies button on the website and clicks it to accept cookies. \n",
        "\n",
        "After that, the process of collecting data for all positions that were passed to the script is started. It is important to clarify that if there are any problems with specific items, the script puts this \"problematic\" item in a special list (skipped list), to which it returns after going through all the items, and again tries to collect information on these items.\n",
        "\n",
        "At the end, the script creates a dataframe from the collected data and writes and saves it as a csv file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jwx27ZbwfqlI"
      },
      "source": [
        "def main(params)\n",
        "    # initialize a list of the possible delays to mimic user interaction with websites\n",
        "    delays = [1, 2, 3, 4, 5]\n",
        "\n",
        "    # initialize a list where we store all collected data\n",
        "    collected_data = []\n",
        "\n",
        "    # list of items to search\n",
        "    items_list = params.items_list\n",
        "\n",
        "    # initalize webdriver options\n",
        "    profile = webdriver.FirefoxProfile()\n",
        "    if params.ua_string != '':\n",
        "        # user agent string\n",
        "        ua_string = params.ua_string\n",
        "        # initialize user agent\n",
        "        user_agent = parse(ua_string)\n",
        "        print(f\"Current user-agent: {user_agent}\")\n",
        "        profile.set_preference(\"general.useragent.override\", ua_string)\n",
        "\n",
        "    PROXY = params.proxy\n",
        "    if PROXY != '':\n",
        "        webdriver.DesiredCapabilities.FIREFOX['proxy'] = {\n",
        "            \"httpProxy\": PROXY,\n",
        "            \"ftpProxy\": PROXY,\n",
        "            \"sslProxy\": PROXY,\n",
        "            \"proxyType\": \"MANUAL\",\n",
        "        }\n",
        "        \n",
        "    \n",
        "    opts = FirefoxOptions()\n",
        "    opts.add_argument(\"--headless\")\n",
        "\n",
        "    # initialize a webdriver\n",
        "    driver = webdriver.Firefox(firefox_options=opts, firefox_profile=profile)\n",
        "    # get the url\n",
        "    driver.get(params.web_page)\n",
        "\n",
        "    # time to wait a response from the page\n",
        "    timeout = 30\n",
        "    # press the button to accept cookies\n",
        "    try:\n",
        "        cookies = WebDriverWait(driver, timeout).until(EC.visibility_of_element_located((By.CLASS_NAME, \"js-confirm-button\")))\n",
        "\n",
        "        delay = np.random.choice(delays)\n",
        "        time.sleep(delay)\n",
        "\n",
        "        cookies.send_keys(Keys.RETURN)  # press ENTER\n",
        "\n",
        "    except TimeoutException:\n",
        "        print(\"Didn't found the button accept cookies.\")\n",
        "        pass\n",
        "\n",
        "    # initialize a list with failed items\n",
        "    skipped_items = []\n",
        "\n",
        "    # collect the data\n",
        "    for item in tqdm(items_list):\n",
        "        print(\"================\")\n",
        "        print(item)\n",
        "        print(\"================\")\n",
        "        print(\"\\n\")\n",
        "\n",
        "        try:\n",
        "            try:\n",
        "                try:\n",
        "                    _ = iteration(driver, item, delays, collected_data)\n",
        "\n",
        "                except:\n",
        "                    _ = iteration(driver, item, delays, collected_data)\n",
        "\n",
        "            except:\n",
        "                try:\n",
        "                    _ = iteration(driver, item, delays, collected_data)\n",
        "\n",
        "                except:\n",
        "                    _ = iteration(driver, item, delays, collected_data)\n",
        "\n",
        "        except:\n",
        "            print(f\"{item} was skipped\")\n",
        "            skipped_items.append(item)\n",
        "            pass\n",
        "\n",
        "    print(\"Writing csv file...\")\n",
        "    df = pd.DataFrame(collected_data)\n",
        "    df.to_csv(f'{params.exp_name}' + '_' + pd.to_datetime('now').strftime(\"%Y-%m-%d %H:%M:%S\") + \".csv\", index=False)\n",
        "    print(\"Writing finished.\")\n",
        "\n",
        "    # close the driver\n",
        "    driver.quit()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDVUv4kWS307"
      },
      "source": [
        "## **Script execution**\n",
        "\n",
        "The code cell below executes the script. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_R0J0lzoS3Ua"
      },
      "source": [
        "if __name__ == '__main__':\n",
        "    parser = get_parser()\n",
        "    params, unknown = parser.parse_known_args()\n",
        "#     params.exp_name = 'test27'\n",
        "#     params.items_list = ['sneakers', 'parfum', 'sandalen', 'horloge', 'rugzak', 'zonnebril', 'kostuum', 'trainingspak', 'badpak', 'jurk', 'overhemd', 'mantel', 'laarzen', 'koptelefoon', 'yogamat', 'sjaal', 'badjas', 'halsketting', 'portemonnee']\n",
        "#     params.web_page = 'https://www.bol.com/'\n",
        "#     params.exec_path = ''\n",
        "    # run the script\n",
        "    main(params)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}